[2022-03-23 08:53:21,960] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-03-02T06:00:00+00:00 [queued]>
[2022-03-23 08:53:21,975] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-03-02T06:00:00+00:00 [queued]>
[2022-03-23 08:53:21,976] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-03-23 08:53:21,976] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-03-23 08:53:21,977] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-03-23 08:53:21,992] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2018-03-02 06:00:00+00:00
[2022-03-23 08:53:22,001] {standard_task_runner.py:52} INFO - Started process 310 to run task
[2022-03-23 08:53:22,005] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'dtc_project_ingest', 'download_dataset_task', 'scheduled__2018-03-02T06:00:00+00:00', '--job-id', '646', '--raw', '--subdir', 'DAGS_FOLDER/project_data_ingestion.py', '--cfg-path', '/tmp/tmpto9bx6ca', '--error-file', '/tmp/tmpup94paqr']
[2022-03-23 08:53:22,007] {standard_task_runner.py:77} INFO - Job 646: Subtask download_dataset_task
[2022-03-23 08:53:22,118] {logging_mixin.py:109} INFO - Running <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-03-02T06:00:00+00:00 [running]> on host 7127e26385ba
[2022-03-23 08:53:22,168] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-03-23 08:53:22,191] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=dtc_project_ingest
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2018-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2018-03-02T06:00:00+00:00
[2022-03-23 08:53:22,193] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-03-23 08:53:22,194] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://s3.amazonaws.com/tripdata/201803-citibike-tripdata.csv.zip > /opt/***/201803-citibike-tripdata.csv.zip']
[2022-03-23 08:53:22,210] {subprocess.py:85} INFO - Output:
[2022-03-23 08:54:47,759] {subprocess.py:93} INFO - Command exited with return code 0
[2022-03-23 08:54:47,785] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=dtc_project_ingest, task_id=download_dataset_task, execution_date=20180302T060000, start_date=20220323T085321, end_date=20220323T085447
[2022-03-23 08:54:47,812] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-03-23 08:54:47,847] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-03-23 15:01:16,041] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-03-02T06:00:00+00:00 [queued]>
[2022-03-23 15:01:16,080] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-03-02T06:00:00+00:00 [queued]>
[2022-03-23 15:01:16,083] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-03-23 15:01:16,086] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-03-23 15:01:16,088] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-03-23 15:01:16,132] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2018-03-02 06:00:00+00:00
[2022-03-23 15:01:16,153] {standard_task_runner.py:52} INFO - Started process 594 to run task
[2022-03-23 15:01:16,172] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'dtc_project_ingest', 'download_dataset_task', 'scheduled__2018-03-02T06:00:00+00:00', '--job-id', '851', '--raw', '--subdir', 'DAGS_FOLDER/project_data_ingestion.py', '--cfg-path', '/tmp/tmph9nnpbz4', '--error-file', '/tmp/tmpy61wzah3']
[2022-03-23 15:01:16,181] {standard_task_runner.py:77} INFO - Job 851: Subtask download_dataset_task
[2022-03-23 15:01:16,334] {logging_mixin.py:109} INFO - Running <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-03-02T06:00:00+00:00 [running]> on host 7127e26385ba
[2022-03-23 15:01:16,465] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-03-23 15:01:16,530] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=dtc_project_ingest
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2018-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2018-03-02T06:00:00+00:00
[2022-03-23 15:01:16,536] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-03-23 15:01:16,539] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://s3.amazonaws.com/tripdata/201803-citibike-tripdata.csv.zip > /opt/***/201803-citibike-tripdata.csv.zip']
[2022-03-23 15:01:16,573] {subprocess.py:85} INFO - Output:
[2022-03-23 15:02:04,864] {subprocess.py:93} INFO - Command exited with return code 0
[2022-03-23 15:02:04,897] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=dtc_project_ingest, task_id=download_dataset_task, execution_date=20180302T060000, start_date=20220323T150116, end_date=20220323T150204
[2022-03-23 15:02:04,942] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-03-23 15:02:04,989] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-03-23 15:17:27,980] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-03-02T06:00:00+00:00 [queued]>
[2022-03-23 15:17:27,999] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-03-02T06:00:00+00:00 [queued]>
[2022-03-23 15:17:28,001] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-03-23 15:17:28,002] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-03-23 15:17:28,003] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-03-23 15:17:28,023] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2018-03-02 06:00:00+00:00
[2022-03-23 15:17:28,034] {standard_task_runner.py:52} INFO - Started process 1413 to run task
[2022-03-23 15:17:28,040] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'dtc_project_ingest', 'download_dataset_task', 'scheduled__2018-03-02T06:00:00+00:00', '--job-id', '871', '--raw', '--subdir', 'DAGS_FOLDER/project_data_ingestion.py', '--cfg-path', '/tmp/tmph5321ned', '--error-file', '/tmp/tmpgbsdh7qu']
[2022-03-23 15:17:28,042] {standard_task_runner.py:77} INFO - Job 871: Subtask download_dataset_task
[2022-03-23 15:17:28,136] {logging_mixin.py:109} INFO - Running <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-03-02T06:00:00+00:00 [running]> on host 7127e26385ba
[2022-03-23 15:17:28,200] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-03-23 15:17:28,234] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=dtc_project_ingest
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2018-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2018-03-02T06:00:00+00:00
[2022-03-23 15:17:28,236] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-03-23 15:17:28,240] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://s3.amazonaws.com/tripdata/201803-citibike-tripdata.csv.zip > /opt/***/201803-citibike-tripdata.csv.zip']
[2022-03-23 15:17:28,270] {subprocess.py:85} INFO - Output:
[2022-03-23 15:18:10,878] {subprocess.py:93} INFO - Command exited with return code 0
[2022-03-23 15:18:11,031] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=dtc_project_ingest, task_id=download_dataset_task, execution_date=20180302T060000, start_date=20220323T151727, end_date=20220323T151811
[2022-03-23 15:18:11,117] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-03-23 15:18:11,192] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-03-23 15:54:37,472] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-03-02T06:00:00+00:00 [queued]>
[2022-03-23 15:54:37,487] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-03-02T06:00:00+00:00 [queued]>
[2022-03-23 15:54:37,488] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-03-23 15:54:37,489] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-03-23 15:54:37,490] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-03-23 15:54:37,506] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2018-03-02 06:00:00+00:00
[2022-03-23 15:54:37,515] {standard_task_runner.py:52} INFO - Started process 3307 to run task
[2022-03-23 15:54:37,520] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'dtc_project_ingest', 'download_dataset_task', 'scheduled__2018-03-02T06:00:00+00:00', '--job-id', '941', '--raw', '--subdir', 'DAGS_FOLDER/project_data_ingestion.py', '--cfg-path', '/tmp/tmpem8zo7ow', '--error-file', '/tmp/tmptha3m2hg']
[2022-03-23 15:54:37,521] {standard_task_runner.py:77} INFO - Job 941: Subtask download_dataset_task
[2022-03-23 15:54:37,590] {logging_mixin.py:109} INFO - Running <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-03-02T06:00:00+00:00 [running]> on host 7127e26385ba
[2022-03-23 15:54:37,635] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-03-23 15:54:37,663] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=dtc_project_ingest
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2018-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2018-03-02T06:00:00+00:00
[2022-03-23 15:54:37,665] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-03-23 15:54:37,666] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://s3.amazonaws.com/tripdata/201803-citibike-tripdata.csv.zip > /opt/***/201803-citibike-tripdata.csv.zip']
[2022-03-23 15:54:37,682] {subprocess.py:85} INFO - Output:
[2022-03-23 15:55:15,018] {subprocess.py:93} INFO - Command exited with return code 0
[2022-03-23 15:55:15,073] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=dtc_project_ingest, task_id=download_dataset_task, execution_date=20180302T060000, start_date=20220323T155437, end_date=20220323T155515
[2022-03-23 15:55:15,126] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-03-23 15:55:15,167] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-03-26 10:29:07,529] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-03-02T06:00:00+00:00 [queued]>
[2022-03-26 10:29:07,547] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-03-02T06:00:00+00:00 [queued]>
[2022-03-26 10:29:07,549] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-03-26 10:29:07,550] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-03-26 10:29:07,551] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-03-26 10:29:07,569] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2018-03-02 06:00:00+00:00
[2022-03-26 10:29:07,579] {standard_task_runner.py:52} INFO - Started process 4888 to run task
[2022-03-26 10:29:07,585] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'dtc_project_ingest', 'download_dataset_task', 'scheduled__2018-03-02T06:00:00+00:00', '--job-id', '1295', '--raw', '--subdir', 'DAGS_FOLDER/project_data_ingestion.py', '--cfg-path', '/tmp/tmpr3ulrmgj', '--error-file', '/tmp/tmpd89k77rq']
[2022-03-26 10:29:07,587] {standard_task_runner.py:77} INFO - Job 1295: Subtask download_dataset_task
[2022-03-26 10:29:07,733] {logging_mixin.py:109} INFO - Running <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-03-02T06:00:00+00:00 [running]> on host c800f4dda314
[2022-03-26 10:29:07,805] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-03-26 10:29:07,850] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=dtc_project_ingest
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2018-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2018-03-02T06:00:00+00:00
[2022-03-26 10:29:07,854] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-03-26 10:29:07,856] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://s3.amazonaws.com/tripdata/201803-citibike-tripdata.csv.zip > /opt/***/201803-citibike-tripdata.csv.zip']
[2022-03-26 10:29:07,876] {subprocess.py:85} INFO - Output:
[2022-03-26 10:30:59,680] {subprocess.py:93} INFO - Command exited with return code 0
[2022-03-26 10:30:59,716] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=dtc_project_ingest, task_id=download_dataset_task, execution_date=20180302T060000, start_date=20220326T102907, end_date=20220326T103059
[2022-03-26 10:30:59,746] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-03-26 10:30:59,803] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-03-26 15:25:18,402] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-03-02T06:00:00+00:00 [queued]>
[2022-03-26 15:25:18,421] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-03-02T06:00:00+00:00 [queued]>
[2022-03-26 15:25:18,422] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-03-26 15:25:18,423] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-03-26 15:25:18,425] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-03-26 15:25:18,447] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2018-03-02 06:00:00+00:00
[2022-03-26 15:25:18,457] {standard_task_runner.py:52} INFO - Started process 19724 to run task
[2022-03-26 15:25:18,471] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'dtc_project_ingest', 'download_dataset_task', 'scheduled__2018-03-02T06:00:00+00:00', '--job-id', '1548', '--raw', '--subdir', 'DAGS_FOLDER/project_data_ingestion.py', '--cfg-path', '/tmp/tmp_efyrovz', '--error-file', '/tmp/tmpylqpn6dp']
[2022-03-26 15:25:18,473] {standard_task_runner.py:77} INFO - Job 1548: Subtask download_dataset_task
[2022-03-26 15:25:18,616] {logging_mixin.py:109} INFO - Running <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-03-02T06:00:00+00:00 [running]> on host c800f4dda314
[2022-03-26 15:25:18,689] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-03-26 15:25:18,725] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=dtc_project_ingest
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2018-03-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2018-03-02T06:00:00+00:00
[2022-03-26 15:25:18,728] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-03-26 15:25:18,730] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://s3.amazonaws.com/tripdata/201803-citibike-tripdata.csv.zip > /opt/***/201803-citibike-tripdata.csv.zip']
[2022-03-26 15:25:18,754] {subprocess.py:85} INFO - Output:
[2022-03-26 15:25:32,718] {subprocess.py:93} INFO - Command exited with return code 0
[2022-03-26 15:25:32,780] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=dtc_project_ingest, task_id=download_dataset_task, execution_date=20180302T060000, start_date=20220326T152518, end_date=20220326T152532
[2022-03-26 15:25:32,845] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-03-26 15:25:32,898] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
