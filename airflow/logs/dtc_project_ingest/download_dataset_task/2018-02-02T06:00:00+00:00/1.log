[2022-03-23 08:51:56,887] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-02-02T06:00:00+00:00 [queued]>
[2022-03-23 08:51:56,948] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-02-02T06:00:00+00:00 [queued]>
[2022-03-23 08:51:56,952] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-03-23 08:51:56,956] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-03-23 08:51:56,959] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-03-23 08:51:57,016] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2018-02-02 06:00:00+00:00
[2022-03-23 08:51:57,031] {standard_task_runner.py:52} INFO - Started process 212 to run task
[2022-03-23 08:51:57,041] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'dtc_project_ingest', 'download_dataset_task', 'scheduled__2018-02-02T06:00:00+00:00', '--job-id', '639', '--raw', '--subdir', 'DAGS_FOLDER/project_data_ingestion.py', '--cfg-path', '/tmp/tmp7elt_r6b', '--error-file', '/tmp/tmpmujjfx3q']
[2022-03-23 08:51:57,044] {standard_task_runner.py:77} INFO - Job 639: Subtask download_dataset_task
[2022-03-23 08:51:57,260] {logging_mixin.py:109} INFO - Running <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-02-02T06:00:00+00:00 [running]> on host 7127e26385ba
[2022-03-23 08:51:57,376] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-03-23 08:51:57,448] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=dtc_project_ingest
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2018-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2018-02-02T06:00:00+00:00
[2022-03-23 08:51:57,454] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-03-23 08:51:57,457] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://s3.amazonaws.com/tripdata/201802-citibike-tripdata.csv.zip > /opt/***/201802-citibike-tripdata.csv.zip']
[2022-03-23 08:51:57,500] {subprocess.py:85} INFO - Output:
[2022-03-23 08:52:58,698] {subprocess.py:93} INFO - Command exited with return code 0
[2022-03-23 08:52:58,759] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=dtc_project_ingest, task_id=download_dataset_task, execution_date=20180202T060000, start_date=20220323T085156, end_date=20220323T085258
[2022-03-23 08:52:58,854] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-03-23 08:52:58,926] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-03-23 15:01:15,207] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-02-02T06:00:00+00:00 [queued]>
[2022-03-23 15:01:15,309] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-02-02T06:00:00+00:00 [queued]>
[2022-03-23 15:01:15,326] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-03-23 15:01:15,328] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-03-23 15:01:15,331] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-03-23 15:01:15,386] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2018-02-02 06:00:00+00:00
[2022-03-23 15:01:15,423] {standard_task_runner.py:52} INFO - Started process 580 to run task
[2022-03-23 15:01:15,467] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'dtc_project_ingest', 'download_dataset_task', 'scheduled__2018-02-02T06:00:00+00:00', '--job-id', '850', '--raw', '--subdir', 'DAGS_FOLDER/project_data_ingestion.py', '--cfg-path', '/tmp/tmpdwnajocz', '--error-file', '/tmp/tmp2p0_67ae']
[2022-03-23 15:01:15,475] {standard_task_runner.py:77} INFO - Job 850: Subtask download_dataset_task
[2022-03-23 15:01:15,776] {logging_mixin.py:109} INFO - Running <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-02-02T06:00:00+00:00 [running]> on host 7127e26385ba
[2022-03-23 15:01:15,954] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-03-23 15:01:16,027] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=dtc_project_ingest
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2018-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2018-02-02T06:00:00+00:00
[2022-03-23 15:01:16,031] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-03-23 15:01:16,037] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://s3.amazonaws.com/tripdata/201802-citibike-tripdata.csv.zip > /opt/***/201802-citibike-tripdata.csv.zip']
[2022-03-23 15:01:16,090] {subprocess.py:85} INFO - Output:
[2022-03-23 15:02:19,429] {subprocess.py:93} INFO - Command exited with return code 0
[2022-03-23 15:02:19,473] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=dtc_project_ingest, task_id=download_dataset_task, execution_date=20180202T060000, start_date=20220323T150115, end_date=20220323T150219
[2022-03-23 15:02:19,506] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-03-23 15:02:19,548] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-03-23 15:12:07,047] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-02-02T06:00:00+00:00 [queued]>
[2022-03-23 15:12:07,066] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-02-02T06:00:00+00:00 [queued]>
[2022-03-23 15:12:07,068] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-03-23 15:12:07,069] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-03-23 15:12:07,070] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-03-23 15:12:07,089] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2018-02-02 06:00:00+00:00
[2022-03-23 15:12:07,098] {standard_task_runner.py:52} INFO - Started process 1149 to run task
[2022-03-23 15:12:07,104] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'dtc_project_ingest', 'download_dataset_task', 'scheduled__2018-02-02T06:00:00+00:00', '--job-id', '863', '--raw', '--subdir', 'DAGS_FOLDER/project_data_ingestion.py', '--cfg-path', '/tmp/tmpdbsvu_2u', '--error-file', '/tmp/tmpt5bb9n8r']
[2022-03-23 15:12:07,107] {standard_task_runner.py:77} INFO - Job 863: Subtask download_dataset_task
[2022-03-23 15:12:07,197] {logging_mixin.py:109} INFO - Running <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-02-02T06:00:00+00:00 [running]> on host 7127e26385ba
[2022-03-23 15:12:07,276] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-03-23 15:12:07,313] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=dtc_project_ingest
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2018-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2018-02-02T06:00:00+00:00
[2022-03-23 15:12:07,317] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-03-23 15:12:07,319] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://s3.amazonaws.com/tripdata/201802-citibike-tripdata.csv.zip > /opt/***/201802-citibike-tripdata.csv.zip']
[2022-03-23 15:12:07,343] {subprocess.py:85} INFO - Output:
[2022-03-23 15:13:12,120] {subprocess.py:93} INFO - Command exited with return code 0
[2022-03-23 15:13:12,158] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=dtc_project_ingest, task_id=download_dataset_task, execution_date=20180202T060000, start_date=20220323T151207, end_date=20220323T151312
[2022-03-23 15:13:12,214] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-03-23 15:13:12,266] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-03-23 15:46:27,830] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-02-02T06:00:00+00:00 [queued]>
[2022-03-23 15:46:27,848] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-02-02T06:00:00+00:00 [queued]>
[2022-03-23 15:46:27,849] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-03-23 15:46:27,850] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-03-23 15:46:27,852] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-03-23 15:46:27,867] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2018-02-02 06:00:00+00:00
[2022-03-23 15:46:27,875] {standard_task_runner.py:52} INFO - Started process 2893 to run task
[2022-03-23 15:46:27,882] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'dtc_project_ingest', 'download_dataset_task', 'scheduled__2018-02-02T06:00:00+00:00', '--job-id', '922', '--raw', '--subdir', 'DAGS_FOLDER/project_data_ingestion.py', '--cfg-path', '/tmp/tmpblu2mp48', '--error-file', '/tmp/tmpp71_ssof']
[2022-03-23 15:46:27,884] {standard_task_runner.py:77} INFO - Job 922: Subtask download_dataset_task
[2022-03-23 15:46:27,957] {logging_mixin.py:109} INFO - Running <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-02-02T06:00:00+00:00 [running]> on host 7127e26385ba
[2022-03-23 15:46:28,008] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-03-23 15:46:28,035] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=dtc_project_ingest
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2018-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2018-02-02T06:00:00+00:00
[2022-03-23 15:46:28,037] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-03-23 15:46:28,039] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://s3.amazonaws.com/tripdata/201802-citibike-tripdata.csv.zip > /opt/***/201802-citibike-tripdata.csv.zip']
[2022-03-23 15:46:28,059] {subprocess.py:85} INFO - Output:
[2022-03-23 15:47:05,739] {subprocess.py:93} INFO - Command exited with return code 0
[2022-03-23 15:47:05,900] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=dtc_project_ingest, task_id=download_dataset_task, execution_date=20180202T060000, start_date=20220323T154627, end_date=20220323T154705
[2022-03-23 15:47:06,053] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-03-23 15:47:06,215] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-03-23 15:53:03,639] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-02-02T06:00:00+00:00 [queued]>
[2022-03-23 15:53:03,659] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-02-02T06:00:00+00:00 [queued]>
[2022-03-23 15:53:03,662] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-03-23 15:53:03,664] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-03-23 15:53:03,666] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-03-23 15:53:03,686] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2018-02-02 06:00:00+00:00
[2022-03-23 15:53:03,696] {standard_task_runner.py:52} INFO - Started process 3223 to run task
[2022-03-23 15:53:03,703] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'dtc_project_ingest', 'download_dataset_task', 'scheduled__2018-02-02T06:00:00+00:00', '--job-id', '934', '--raw', '--subdir', 'DAGS_FOLDER/project_data_ingestion.py', '--cfg-path', '/tmp/tmpc731h43g', '--error-file', '/tmp/tmpyxst7s4u']
[2022-03-23 15:53:03,705] {standard_task_runner.py:77} INFO - Job 934: Subtask download_dataset_task
[2022-03-23 15:53:03,810] {logging_mixin.py:109} INFO - Running <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-02-02T06:00:00+00:00 [running]> on host 7127e26385ba
[2022-03-23 15:53:03,890] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-03-23 15:53:03,927] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=dtc_project_ingest
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2018-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2018-02-02T06:00:00+00:00
[2022-03-23 15:53:03,930] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-03-23 15:53:03,933] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://s3.amazonaws.com/tripdata/201802-citibike-tripdata.csv.zip > /opt/***/201802-citibike-tripdata.csv.zip']
[2022-03-23 15:53:03,957] {subprocess.py:85} INFO - Output:
[2022-03-23 15:53:41,554] {subprocess.py:93} INFO - Command exited with return code 0
[2022-03-23 15:53:41,607] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=dtc_project_ingest, task_id=download_dataset_task, execution_date=20180202T060000, start_date=20220323T155303, end_date=20220323T155341
[2022-03-23 15:53:41,651] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-03-23 15:53:41,703] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-03-26 10:26:44,351] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-02-02T06:00:00+00:00 [queued]>
[2022-03-26 10:26:44,380] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-02-02T06:00:00+00:00 [queued]>
[2022-03-26 10:26:44,381] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-03-26 10:26:44,382] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-03-26 10:26:44,384] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-03-26 10:26:44,404] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2018-02-02 06:00:00+00:00
[2022-03-26 10:26:44,417] {standard_task_runner.py:52} INFO - Started process 4737 to run task
[2022-03-26 10:26:44,426] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'dtc_project_ingest', 'download_dataset_task', 'scheduled__2018-02-02T06:00:00+00:00', '--job-id', '1286', '--raw', '--subdir', 'DAGS_FOLDER/project_data_ingestion.py', '--cfg-path', '/tmp/tmphcwn2q8k', '--error-file', '/tmp/tmpgck2pm6d']
[2022-03-26 10:26:44,429] {standard_task_runner.py:77} INFO - Job 1286: Subtask download_dataset_task
[2022-03-26 10:26:44,512] {logging_mixin.py:109} INFO - Running <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-02-02T06:00:00+00:00 [running]> on host c800f4dda314
[2022-03-26 10:26:44,561] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-03-26 10:26:44,599] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=dtc_project_ingest
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2018-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2018-02-02T06:00:00+00:00
[2022-03-26 10:26:44,603] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-03-26 10:26:44,604] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://s3.amazonaws.com/tripdata/201802-citibike-tripdata.csv.zip > /opt/***/201802-citibike-tripdata.csv.zip']
[2022-03-26 10:26:44,622] {subprocess.py:85} INFO - Output:
[2022-03-26 10:28:13,225] {subprocess.py:93} INFO - Command exited with return code 0
[2022-03-26 10:28:13,258] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=dtc_project_ingest, task_id=download_dataset_task, execution_date=20180202T060000, start_date=20220326T102644, end_date=20220326T102813
[2022-03-26 10:28:13,322] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-03-26 10:28:13,369] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-03-26 15:24:04,665] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-02-02T06:00:00+00:00 [queued]>
[2022-03-26 15:24:04,680] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-02-02T06:00:00+00:00 [queued]>
[2022-03-26 15:24:04,682] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-03-26 15:24:04,682] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-03-26 15:24:04,683] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-03-26 15:24:04,701] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2018-02-02 06:00:00+00:00
[2022-03-26 15:24:04,714] {standard_task_runner.py:52} INFO - Started process 19637 to run task
[2022-03-26 15:24:04,724] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'dtc_project_ingest', 'download_dataset_task', 'scheduled__2018-02-02T06:00:00+00:00', '--job-id', '1541', '--raw', '--subdir', 'DAGS_FOLDER/project_data_ingestion.py', '--cfg-path', '/tmp/tmppqwqibah', '--error-file', '/tmp/tmpskkmw198']
[2022-03-26 15:24:04,726] {standard_task_runner.py:77} INFO - Job 1541: Subtask download_dataset_task
[2022-03-26 15:24:04,830] {logging_mixin.py:109} INFO - Running <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2018-02-02T06:00:00+00:00 [running]> on host c800f4dda314
[2022-03-26 15:24:04,881] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-03-26 15:24:04,912] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=dtc_project_ingest
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2018-02-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2018-02-02T06:00:00+00:00
[2022-03-26 15:24:04,916] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-03-26 15:24:04,919] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://s3.amazonaws.com/tripdata/201802-citibike-tripdata.csv.zip > /opt/***/201802-citibike-tripdata.csv.zip']
[2022-03-26 15:24:04,940] {subprocess.py:85} INFO - Output:
[2022-03-26 15:24:27,329] {subprocess.py:93} INFO - Command exited with return code 0
[2022-03-26 15:24:27,846] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=dtc_project_ingest, task_id=download_dataset_task, execution_date=20180202T060000, start_date=20220326T152404, end_date=20220326T152427
[2022-03-26 15:24:28,107] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-03-26 15:24:28,494] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
