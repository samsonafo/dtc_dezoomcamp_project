[2022-03-21 23:22:20,472] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [queued]>
[2022-03-21 23:22:20,496] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [queued]>
[2022-03-21 23:22:20,498] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-03-21 23:22:20,500] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-03-21 23:22:20,504] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-03-21 23:22:20,541] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2019-11-02 06:00:00+00:00
[2022-03-21 23:22:20,555] {standard_task_runner.py:52} INFO - Started process 2621 to run task
[2022-03-21 23:22:20,566] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'dtc_project_ingest', 'download_dataset_task', 'scheduled__2019-11-02T06:00:00+00:00', '--job-id', '586', '--raw', '--subdir', 'DAGS_FOLDER/project_data_ingestion.py', '--cfg-path', '/tmp/tmpoeci5hdj', '--error-file', '/tmp/tmpypf6nv9u']
[2022-03-21 23:22:20,568] {standard_task_runner.py:77} INFO - Job 586: Subtask download_dataset_task
[2022-03-21 23:22:20,708] {logging_mixin.py:109} INFO - Running <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [running]> on host b91e76d7fa3b
[2022-03-21 23:22:20,778] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-03-21 23:22:20,816] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=dtc_project_ingest
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2019-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-11-02T06:00:00+00:00
[2022-03-21 23:22:20,819] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-03-21 23:22:20,821] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://s3.amazonaws.com/tripdata/201911-citibike-tripdata.csv.zip > /opt/***/201911-citibike-tripdata.csv.zip']
[2022-03-21 23:22:20,843] {subprocess.py:85} INFO - Output:
[2022-03-21 23:23:21,696] {local_task_job.py:212} WARNING - State of this instance has been externally set to failed. Terminating instance.
[2022-03-21 23:23:21,700] {process_utils.py:124} INFO - Sending Signals.SIGTERM to group 2621. PIDs of all processes in the group: [2623, 2624, 2621]
[2022-03-21 23:23:21,701] {process_utils.py:75} INFO - Sending the signal Signals.SIGTERM to group 2621
[2022-03-21 23:23:21,702] {taskinstance.py:1408} ERROR - Received SIGTERM. Terminating subprocesses.
[2022-03-21 23:23:21,703] {subprocess.py:99} INFO - Sending SIGTERM signal to process group
[2022-03-21 23:23:21,837] {process_utils.py:70} INFO - Process psutil.Process(pid=2623, status='terminated', started='23:22:20') (2623) terminated with exit code None
[2022-03-21 23:23:21,838] {process_utils.py:70} INFO - Process psutil.Process(pid=2621, status='terminated', exitcode=0, started='23:22:20') (2621) terminated with exit code 0
[2022-03-21 23:23:21,840] {process_utils.py:70} INFO - Process psutil.Process(pid=2624, status='terminated', started='23:22:20') (2624) terminated with exit code None
[2022-03-23 09:14:18,032] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [queued]>
[2022-03-23 09:14:18,044] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [queued]>
[2022-03-23 09:14:18,045] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-03-23 09:14:18,046] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-03-23 09:14:18,046] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-03-23 09:14:18,060] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2019-11-02 06:00:00+00:00
[2022-03-23 09:14:18,066] {standard_task_runner.py:52} INFO - Started process 1709 to run task
[2022-03-23 09:14:18,071] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'dtc_project_ingest', 'download_dataset_task', 'scheduled__2019-11-02T06:00:00+00:00', '--job-id', '724', '--raw', '--subdir', 'DAGS_FOLDER/project_data_ingestion.py', '--cfg-path', '/tmp/tmpx7feftrz', '--error-file', '/tmp/tmpisw4_v13']
[2022-03-23 09:14:18,074] {standard_task_runner.py:77} INFO - Job 724: Subtask download_dataset_task
[2022-03-23 09:14:18,146] {logging_mixin.py:109} INFO - Running <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [running]> on host 7127e26385ba
[2022-03-23 09:14:18,195] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-03-23 09:14:18,217] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=dtc_project_ingest
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2019-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-11-02T06:00:00+00:00
[2022-03-23 09:14:18,218] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-03-23 09:14:18,219] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://s3.amazonaws.com/tripdata/201911-citibike-tripdata.csv.zip > /opt/***/201911-citibike-tripdata.csv.zip']
[2022-03-23 09:14:18,235] {subprocess.py:85} INFO - Output:
[2022-03-23 09:16:16,034] {subprocess.py:93} INFO - Command exited with return code 0
[2022-03-23 09:16:16,063] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=dtc_project_ingest, task_id=download_dataset_task, execution_date=20191102T060000, start_date=20220323T091418, end_date=20220323T091616
[2022-03-23 09:16:16,128] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-03-23 09:16:16,167] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-03-23 16:21:57,490] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [queued]>
[2022-03-23 16:21:57,501] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [queued]>
[2022-03-23 16:21:57,502] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-03-23 16:21:57,503] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-03-23 16:21:57,504] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-03-23 16:21:57,515] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2019-11-02 06:00:00+00:00
[2022-03-23 16:21:57,522] {standard_task_runner.py:52} INFO - Started process 5032 to run task
[2022-03-23 16:21:57,526] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'dtc_project_ingest', 'download_dataset_task', 'scheduled__2019-11-02T06:00:00+00:00', '--job-id', '1035', '--raw', '--subdir', 'DAGS_FOLDER/project_data_ingestion.py', '--cfg-path', '/tmp/tmptbrd7qll', '--error-file', '/tmp/tmpotd3ekvk']
[2022-03-23 16:21:57,528] {standard_task_runner.py:77} INFO - Job 1035: Subtask download_dataset_task
[2022-03-23 16:21:57,593] {logging_mixin.py:109} INFO - Running <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [running]> on host 7127e26385ba
[2022-03-23 16:21:57,640] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-03-23 16:21:57,664] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=dtc_project_ingest
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2019-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-11-02T06:00:00+00:00
[2022-03-23 16:21:57,666] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-03-23 16:21:57,667] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://s3.amazonaws.com/tripdata/201911-citibike-tripdata.csv.zip > /opt/***/201911-citibike-tripdata.csv.zip']
[2022-03-23 16:21:57,682] {subprocess.py:85} INFO - Output:
[2022-03-23 16:24:18,804] {subprocess.py:93} INFO - Command exited with return code 0
[2022-03-23 16:24:18,860] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=dtc_project_ingest, task_id=download_dataset_task, execution_date=20191102T060000, start_date=20220323T162157, end_date=20220323T162418
[2022-03-23 16:24:18,908] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-03-23 16:24:18,953] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-03-26 11:11:53,836] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [queued]>
[2022-03-26 11:11:53,851] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [queued]>
[2022-03-26 11:11:53,852] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-03-26 11:11:53,853] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-03-26 11:11:53,854] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-03-26 11:11:53,870] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2019-11-02 06:00:00+00:00
[2022-03-26 11:11:53,878] {standard_task_runner.py:52} INFO - Started process 7263 to run task
[2022-03-26 11:11:53,885] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'dtc_project_ingest', 'download_dataset_task', 'scheduled__2019-11-02T06:00:00+00:00', '--job-id', '1393', '--raw', '--subdir', 'DAGS_FOLDER/project_data_ingestion.py', '--cfg-path', '/tmp/tmpk644nhyb', '--error-file', '/tmp/tmpddxocue9']
[2022-03-26 11:11:53,886] {standard_task_runner.py:77} INFO - Job 1393: Subtask download_dataset_task
[2022-03-26 11:11:53,975] {logging_mixin.py:109} INFO - Running <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [running]> on host c800f4dda314
[2022-03-26 11:11:54,032] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-03-26 11:11:54,067] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=dtc_project_ingest
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2019-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-11-02T06:00:00+00:00
[2022-03-26 11:11:54,070] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-03-26 11:11:54,072] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://s3.amazonaws.com/tripdata/201911-citibike-tripdata.csv.zip > /opt/***/201911-citibike-tripdata.csv.zip']
[2022-03-26 11:11:54,093] {subprocess.py:85} INFO - Output:
[2022-03-26 11:15:51,011] {subprocess.py:93} INFO - Command exited with return code 0
[2022-03-26 11:15:51,067] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=dtc_project_ingest, task_id=download_dataset_task, execution_date=20191102T060000, start_date=20220326T111153, end_date=20220326T111551
[2022-03-26 11:15:51,179] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-03-26 11:15:51,250] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-03-26 15:39:37,234] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [queued]>
[2022-03-26 15:39:37,250] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [queued]>
[2022-03-26 15:39:37,251] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-03-26 15:39:37,253] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-03-26 15:39:37,255] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-03-26 15:39:37,273] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2019-11-02 06:00:00+00:00
[2022-03-26 15:39:37,281] {standard_task_runner.py:52} INFO - Started process 20730 to run task
[2022-03-26 15:39:37,293] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'dtc_project_ingest', 'download_dataset_task', 'scheduled__2019-11-02T06:00:00+00:00', '--job-id', '1628', '--raw', '--subdir', 'DAGS_FOLDER/project_data_ingestion.py', '--cfg-path', '/tmp/tmp4647_n0k', '--error-file', '/tmp/tmpft262buj']
[2022-03-26 15:39:37,295] {standard_task_runner.py:77} INFO - Job 1628: Subtask download_dataset_task
[2022-03-26 15:39:37,386] {logging_mixin.py:109} INFO - Running <TaskInstance: dtc_project_ingest.download_dataset_task scheduled__2019-11-02T06:00:00+00:00 [running]> on host c800f4dda314
[2022-03-26 15:39:37,446] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152: AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
  warnings.warn(_create_deprecation_warning(key, self._deprecation_replacements[key]))

[2022-03-26 15:39:37,476] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=dtc_project_ingest
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2019-11-02T06:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-11-02T06:00:00+00:00
[2022-03-26 15:39:37,479] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-03-26 15:39:37,480] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSL https://s3.amazonaws.com/tripdata/201911-citibike-tripdata.csv.zip > /opt/***/201911-citibike-tripdata.csv.zip']
[2022-03-26 15:39:37,498] {subprocess.py:85} INFO - Output:
[2022-03-26 15:40:23,246] {subprocess.py:93} INFO - Command exited with return code 0
[2022-03-26 15:40:23,336] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=dtc_project_ingest, task_id=download_dataset_task, execution_date=20191102T060000, start_date=20220326T153937, end_date=20220326T154023
[2022-03-26 15:40:23,390] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-03-26 15:40:23,444] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
